name: 36Kr News Crawler

on:
  schedule:
    # 每天凌晨1点运行 (UTC时间，对应北京时间9点)
    - cron: '0 1 * * *'
  # 也允许手动触发工作流
  workflow_dispatch:
    inputs:
      days_ago:
        description: '获取几天前的新闻(0=今天，1=昨天)'
        required: true
        default: '0'
        type: choice
        options:
          - '0'
          - '1'
          - '2'
          - '3'
          - '7'
      max_pages:
        description: '最多获取页数'
        required: true
        default: '5'
        type: string
      page_size:
        description: '每页新闻数量'
        required: true
        default: '100'
        type: string

# 添加权限配置
permissions:
  contents: write

jobs:
  crawl-36kr:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests
          
      - name: Run crawler (scheduled)
        if: github.event_name == 'schedule'
        run: |
          # 创建数据目录
          mkdir -p ./data
          # 抓取昨天的新闻(为确保一天的新闻都已发布完成)
          python 36kr.py --days 1 --pages 10 --size 100 --dir ./data
          
      - name: Run crawler (manual)
        if: github.event_name == 'workflow_dispatch'
        run: |
          # 创建数据目录
          mkdir -p ./data
          # 使用用户输入的参数
          python 36kr.py --days ${{ github.event.inputs.days_ago }} --pages ${{ github.event.inputs.max_pages }} --size ${{ github.event.inputs.page_size }} --dir ./data
          
      - name: Push to data branch
        # 将结果推送到专门的data分支
        run: |
          # 配置Git
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          
          # 创建时间戳目录防止冲突
          TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
          mkdir -p ./archive/$TIMESTAMP
          cp -r ./data/* ./archive/$TIMESTAMP/
          
          # 添加README如果不存在
          if [ ! -f README.md ]; then
            echo "# 36氪新闻数据" > README.md
            echo "此仓库通过GitHub Actions自动抓取36氪网站的最新新闻。" >> README.md
            echo "数据每天自动更新。" >> README.md
          fi
          
          # 添加所有更改
          git add ./data ./archive README.md
          
          # 提交更改
          git commit -m "Update 36kr news data: $TIMESTAMP" || echo "No changes to commit"
          
          # 推送到原分支
          git push origin HEAD || (git pull --rebase && git push origin HEAD)
          
      - name: Archive crawling results
        uses: actions/upload-artifact@v4
        with:
          name: 36kr-news-data
          path: ./data/
          retention-days: 7
